{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ðŸ“– Bible Studies",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcLSjgrQWePA",
        "outputId": "56585308-6a0c-4de9-cf0e-fc8b9783eabf"
      },
      "source": [
        "#import nltk and corpus\n",
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "\n",
        "#import numpy and pandas\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#read the bible and make a frequency plot of the most frequent words\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "bible = nltk.corpus.gutenberg.words('bible-kjv.txt')\n",
        "fdist = nltk.FreqDist(w.lower() for w in bible)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yzvRL_OWiPS"
      },
      "source": [
        "from string import punctuation\n",
        "\n",
        "#read the bible and make a frequency plot of the most frequent words\n",
        "bible = nltk.corpus.gutenberg.words('bible-kjv.txt')\n",
        "fdist = nltk.FreqDist(w.lower() for w in bible)\n",
        "\n",
        "# make a list of the most frequent words excluding the stopwords\n",
        "most_freq_words = [w for w in fdist.keys() if w not in nltk.corpus.stopwords.words('english') and not w.isdigit()]\n",
        "most_freq_words = [w for w in most_freq_words if w not in punctuation]\n",
        "\n",
        "# make a dataframe of the most frequent words\n",
        "df = pd.DataFrame(most_freq_words, columns=['word'])\n",
        "\n",
        "# add a column for the frequency\n",
        "df['freq'] = df['word'].map(fdist)\n",
        "# add a column for the percentage\n",
        "df['percent'] = df['freq']/df['freq'].sum()\n",
        "# add a column for the rank\n",
        "df['rank'] = df['freq'].rank(ascending=False)\n",
        "# add a column for the cumulative frequency\n",
        "df['cum_freq'] = df['freq'].cumsum()\n",
        "# add a column for the cumulative percentage\n",
        "df['cum_percent'] = df['cum_freq']/df['freq'].sum()\n",
        "# add a column for the log rank\n",
        "df['log_rank'] = np.log(df['rank'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "N6fhC5N9Wj44",
        "outputId": "e277c471-cf42-45ef-da9b-e53fcbdce4e2"
      },
      "source": [
        "df.sort_values(by='rank', ascending=True)[:30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>freq</th>\n",
              "      <th>percent</th>\n",
              "      <th>rank</th>\n",
              "      <th>cum_freq</th>\n",
              "      <th>cum_percent</th>\n",
              "      <th>log_rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>shall</td>\n",
              "      <td>9838</td>\n",
              "      <td>0.026224</td>\n",
              "      <td>1.0</td>\n",
              "      <td>78463</td>\n",
              "      <td>0.209149</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>unto</td>\n",
              "      <td>8997</td>\n",
              "      <td>0.023982</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37277</td>\n",
              "      <td>0.099365</td>\n",
              "      <td>0.693147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>lord</td>\n",
              "      <td>7964</td>\n",
              "      <td>0.021229</td>\n",
              "      <td>3.0</td>\n",
              "      <td>88838</td>\n",
              "      <td>0.236805</td>\n",
              "      <td>1.098612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>thou</td>\n",
              "      <td>5474</td>\n",
              "      <td>0.014591</td>\n",
              "      <td>4.0</td>\n",
              "      <td>105123</td>\n",
              "      <td>0.280214</td>\n",
              "      <td>1.386294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>thy</td>\n",
              "      <td>4600</td>\n",
              "      <td>0.012262</td>\n",
              "      <td>5.0</td>\n",
              "      <td>131649</td>\n",
              "      <td>0.350921</td>\n",
              "      <td>1.609438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>god</td>\n",
              "      <td>4472</td>\n",
              "      <td>0.011920</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9713</td>\n",
              "      <td>0.025891</td>\n",
              "      <td>1.791759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>said</td>\n",
              "      <td>3999</td>\n",
              "      <td>0.010660</td>\n",
              "      <td>7.0</td>\n",
              "      <td>20059</td>\n",
              "      <td>0.053469</td>\n",
              "      <td>1.945910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>ye</td>\n",
              "      <td>3983</td>\n",
              "      <td>0.010617</td>\n",
              "      <td>8.0</td>\n",
              "      <td>121246</td>\n",
              "      <td>0.323191</td>\n",
              "      <td>2.079442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>thee</td>\n",
              "      <td>3827</td>\n",
              "      <td>0.010201</td>\n",
              "      <td>9.0</td>\n",
              "      <td>135951</td>\n",
              "      <td>0.362388</td>\n",
              "      <td>2.197225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>upon</td>\n",
              "      <td>2748</td>\n",
              "      <td>0.007325</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14712</td>\n",
              "      <td>0.039216</td>\n",
              "      <td>2.302585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>man</td>\n",
              "      <td>2735</td>\n",
              "      <td>0.007290</td>\n",
              "      <td>11.0</td>\n",
              "      <td>66027</td>\n",
              "      <td>0.176000</td>\n",
              "      <td>2.397895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1724</th>\n",
              "      <td>israel</td>\n",
              "      <td>2575</td>\n",
              "      <td>0.006864</td>\n",
              "      <td>12.0</td>\n",
              "      <td>276412</td>\n",
              "      <td>0.736798</td>\n",
              "      <td>2.484907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>2543</td>\n",
              "      <td>0.006779</td>\n",
              "      <td>13.0</td>\n",
              "      <td>2543</td>\n",
              "      <td>0.006779</td>\n",
              "      <td>2.564949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>son</td>\n",
              "      <td>2392</td>\n",
              "      <td>0.006376</td>\n",
              "      <td>14.0</td>\n",
              "      <td>163510</td>\n",
              "      <td>0.435849</td>\n",
              "      <td>2.639057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>hath</td>\n",
              "      <td>2264</td>\n",
              "      <td>0.006035</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54876</td>\n",
              "      <td>0.146276</td>\n",
              "      <td>2.708050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>people</td>\n",
              "      <td>2143</td>\n",
              "      <td>0.005712</td>\n",
              "      <td>16.0</td>\n",
              "      <td>204577</td>\n",
              "      <td>0.545316</td>\n",
              "      <td>2.772589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>came</td>\n",
              "      <td>2093</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>17.0</td>\n",
              "      <td>152108</td>\n",
              "      <td>0.405456</td>\n",
              "      <td>2.833213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>house</td>\n",
              "      <td>2024</td>\n",
              "      <td>0.005395</td>\n",
              "      <td>18.0</td>\n",
              "      <td>184754</td>\n",
              "      <td>0.492476</td>\n",
              "      <td>2.890372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>come</td>\n",
              "      <td>1971</td>\n",
              "      <td>0.005254</td>\n",
              "      <td>19.0</td>\n",
              "      <td>159406</td>\n",
              "      <td>0.424909</td>\n",
              "      <td>2.944439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>one</td>\n",
              "      <td>1969</td>\n",
              "      <td>0.005249</td>\n",
              "      <td>20.0</td>\n",
              "      <td>39246</td>\n",
              "      <td>0.104613</td>\n",
              "      <td>2.995732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>children</td>\n",
              "      <td>1821</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>21.0</td>\n",
              "      <td>141921</td>\n",
              "      <td>0.378302</td>\n",
              "      <td>3.044522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>also</td>\n",
              "      <td>1769</td>\n",
              "      <td>0.004715</td>\n",
              "      <td>22.0</td>\n",
              "      <td>51765</td>\n",
              "      <td>0.137984</td>\n",
              "      <td>3.091042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>day</td>\n",
              "      <td>1743</td>\n",
              "      <td>0.004646</td>\n",
              "      <td>23.0</td>\n",
              "      <td>24922</td>\n",
              "      <td>0.066432</td>\n",
              "      <td>3.135494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>land</td>\n",
              "      <td>1718</td>\n",
              "      <td>0.004579</td>\n",
              "      <td>24.0</td>\n",
              "      <td>41751</td>\n",
              "      <td>0.111291</td>\n",
              "      <td>3.178054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>men</td>\n",
              "      <td>1677</td>\n",
              "      <td>0.004470</td>\n",
              "      <td>25.0</td>\n",
              "      <td>168726</td>\n",
              "      <td>0.449753</td>\n",
              "      <td>3.218876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>shalt</td>\n",
              "      <td>1616</td>\n",
              "      <td>0.004308</td>\n",
              "      <td>26.0</td>\n",
              "      <td>107525</td>\n",
              "      <td>0.286616</td>\n",
              "      <td>3.258097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>let</td>\n",
              "      <td>1511</td>\n",
              "      <td>0.004028</td>\n",
              "      <td>27.0</td>\n",
              "      <td>21570</td>\n",
              "      <td>0.057497</td>\n",
              "      <td>3.295837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>go</td>\n",
              "      <td>1492</td>\n",
              "      <td>0.003977</td>\n",
              "      <td>28.0</td>\n",
              "      <td>139554</td>\n",
              "      <td>0.371992</td>\n",
              "      <td>3.332205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>hand</td>\n",
              "      <td>1466</td>\n",
              "      <td>0.003908</td>\n",
              "      <td>29.0</td>\n",
              "      <td>144654</td>\n",
              "      <td>0.385587</td>\n",
              "      <td>3.367296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>us</td>\n",
              "      <td>1451</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>30.0</td>\n",
              "      <td>62236</td>\n",
              "      <td>0.165895</td>\n",
              "      <td>3.401197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          word  freq   percent  rank  cum_freq  cum_percent  log_rank\n",
              "118      shall  9838  0.026224   1.0     78463     0.209149  0.000000\n",
              "42        unto  8997  0.023982   2.0     37277     0.099365  0.693147\n",
              "133       lord  7964  0.021229   3.0     88838     0.236805  1.098612\n",
              "189       thou  5474  0.014591   4.0    105123     0.280214  1.386294\n",
              "259        thy  4600  0.012262   5.0    131649     0.350921  1.609438\n",
              "11         god  4472  0.011920   6.0      9713     0.025891  1.791759\n",
              "25        said  3999  0.010660   7.0     20059     0.053469  1.945910\n",
              "232         ye  3983  0.010617   8.0    121246     0.323191  2.079442\n",
              "262       thee  3827  0.010201   9.0    135951     0.362388  2.197225\n",
              "19        upon  2748  0.007325  10.0     14712     0.039216  2.302585\n",
              "104        man  2735  0.007290  11.0     66027     0.176000  2.397895\n",
              "1724    israel  2575  0.006864  12.0    276412     0.736798  2.484907\n",
              "0         king  2543  0.006779  13.0      2543     0.006779  2.564949\n",
              "367        son  2392  0.006376  14.0    163510     0.435849  2.639057\n",
              "80        hath  2264  0.006035  15.0     54876     0.146276  2.708050\n",
              "736     people  2143  0.005712  16.0    204577     0.545316  2.772589\n",
              "319       came  2093  0.005579  17.0    152108     0.405456  2.833213\n",
              "492      house  2024  0.005395  18.0    184754     0.492476  2.890372\n",
              "352       come  1971  0.005254  19.0    159406     0.424909  2.944439\n",
              "43         one  1969  0.005249  20.0     39246     0.104613  2.995732\n",
              "281   children  1821  0.004854  21.0    141921     0.378302  3.044522\n",
              "74        also  1769  0.004715  22.0     51765     0.137984  3.091042\n",
              "31         day  1743  0.004646  23.0     24922     0.066432  3.135494\n",
              "46        land  1718  0.004579  24.0     41751     0.111291  3.178054\n",
              "406        men  1677  0.004470  25.0    168726     0.449753  3.218876\n",
              "193      shalt  1616  0.004308  26.0    107525     0.286616  3.258097\n",
              "26         let  1511  0.004028  27.0     21570     0.057497  3.295837\n",
              "273         go  1492  0.003977  28.0    139554     0.371992  3.332205\n",
              "295       hand  1466  0.003908  29.0    144654     0.385587  3.367296\n",
              "102         us  1451  0.003868  30.0     62236     0.165895  3.401197"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LrWsJYuWlI8"
      },
      "source": [
        "def markov_chain(text):\n",
        "    \"\"\"The input is a string of text and the output will be a dictionary with each word as\n",
        "       a key and each value as the list of words that come after the key in the text.\"\"\"\n",
        "    \n",
        "    # Tokenize the text by word if text is a list and if text is not a list\n",
        "    # split by space\n",
        "    list_text = text if type(text) == list else text.split(\" \")\n",
        "    \n",
        "    # Create an empty dictionary to hold the word pairs\n",
        "    word_dict = {}\n",
        "    \n",
        "    # Create a list of tuples by pairing the words with the words that follow them\n",
        "    for current_word, next_word in zip(list_text, list_text[1:]):\n",
        "        \n",
        "        # Create a new key value pair if current_word is not already a key in the word_dict\n",
        "        if current_word not in word_dict.keys():\n",
        "            word_dict[current_word] = [next_word]\n",
        "        \n",
        "        # Add the next word to the list of values for the current word key in the word_dict\n",
        "        else:\n",
        "            word_dict[current_word].append(next_word)\n",
        "    \n",
        "    # return the dictionary\n",
        "    return word_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCWL-dTaWm4c",
        "outputId": "0e8b5f83-5392-43e0-d136-54ab32aefa01"
      },
      "source": [
        "\n",
        "bible_list = list(bible)\n",
        "\n",
        "# Create the dictionary for the word \"I\"\n",
        "bible_dict = markov_chain(bible_list)\n",
        "\n",
        "# Create a function that generates sentences\n",
        "def generate_sentence(chain, count=15):\n",
        "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
        "       along with the number of words you would like to see in your generated sentence.'''\n",
        "\n",
        "    # Capitalize the first word\n",
        "    word1 = np.random.choice(list(chain.keys()))\n",
        "    sentence = word1.capitalize()\n",
        "\n",
        "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
        "    for i in range(count-1):\n",
        "        word2 = np.random.choice(chain[word1])\n",
        "        word1 = word2\n",
        "        sentence += ' ' + word2\n",
        "\n",
        "    # End it with a period\n",
        "    sentence += '.'\n",
        "    return(sentence)\n",
        "\n",
        "# Generate sentences from the bible\n",
        "for i in range(3):\n",
        "    print(generate_sentence(bible_dict))\n",
        "\n",
        "# Create a function to generate a paragraph\n",
        "def generate_paragraph(chain, count=4, sent_count=4):\n",
        "    '''Input a dictionary in the format of key = current word, value = list of next words\n",
        "       along with the number of words you would like to see in your generated paragraph.'''\n",
        "    \n",
        "    # Capitalize the first word\n",
        "    word1 = np.random.choice(list(chain.keys()))\n",
        "    paragraph = word1.capitalize()\n",
        "\n",
        "    # Generate the second word from the value list. Set the new word as the first word. Repeat.\n",
        "    for i in range(count-1):\n",
        "        word2 = np.random.choice(chain[word1])\n",
        "        word1 = word2\n",
        "        paragraph += ' ' + word2\n",
        "\n",
        "    # End it with a period\n",
        "    paragraph += '.'\n",
        "    \n",
        "    # Generate sentences from the paragraph\n",
        "    for i in range(sent_count):\n",
        "        paragraph += ' ' + generate_sentence(chain)\n",
        "    \n",
        "    return(paragraph)\n",
        "\n",
        "# Generate paragraphs from the bible\n",
        "for i in range(10):\n",
        "    print(generate_paragraph(bible_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaves : 8 : 23 Am I command them that doeth good conversation received :.\n",
            "Asketh of fire unto all the LORD hath filled with death ; but woe also.\n",
            "Preservest man should not strawed : 11 Again , to the guard ; that thou.\n",
            "Licked up : 15. Geba ; they shouted with a man , to let it for the LORD .. Fragments that came and all those husbandmen of thy mother and entered into the east. Screech owl , I will I will I pray for a great unto one that. Firebrand plucked away the eye shall have I shall be of Beor to abide over.\n",
            "Adjured the host of. Hatita , to mourn , Go ye gave her , and , 10 All the. Hupham , how shall measure , which provoketh to the truth of David was a. Freewill offering , because thou , his house of hewn stone to pass by might. Appearing of men of the LORD . 2 : and when the LORD God :.\n",
            "Galley with fir trees. Seated ; now do these things .) 8 : but of Canaan , and he. Benefactors . 28 : 17 And thou answer us not do justice and spoiled :. Kithlish , and Kedesh in the heathen , a great toe of the son ?. Shutteth ; and in them shall kill the wilderness , lest by the camels ..\n",
            "Carcas , were about. Wherewith the second , and kneeled down my name of the nations were conversant with. Stopped all thy name he went forth to the Philistines : 39 And David '. Taken in the Bethlehemite , the word that same , and made he hath shewed. Stepped in divers colours . 19 : 10 For if I shall go for me.\n",
            "Fell down , that. Dew of king Joram lay thee that thou hast cast every man find mercy ,. Avouched thee . 51 : for the inheritance unto me about them , saith the. Questioned with her from the caves , and said unto heaven : for there be. Ellasar ; they followed not withhold from the vision in the light of the priest.\n",
            "Manaen , that our. Ahaziah his belly , and Menahem , while , and to the family of the. Sheal , and I have we have satisfied ; as it shall burn upon the. Seleucia ; and shalt speak , and he sat thereon unto good of their tents. Eat no dealings by the gods . 16 : 22 And Obededom were our feet.\n",
            "Decked herself , that. Hew down my sanctuary and shall bear it came to be abolished in the wilderness. Fifteen cubits on the names , saying , and they sacrificed sacrifices for they builded. Debt . 60 : he shall send a lamentation , by reason of them ;. Thickets of the heart to wife , that being the voice of an ephah for.\n",
            "Such knowledge from heaven. Bulrushes upon me . 9 And thou that go out of the voice of rich. Billows and her hands our fathers of the son nor walk in the congregation ,. Confidences , and it should be forgiven you ? 6 : 20 He that I. Atarah ; for the other saith unto the lilies , and fowls of God before.\n",
            "Bred worms , and. Antiquity is an inheritance of singing women therein . 13 : of words of a. Resting place to fail , and will go and shall surely he overlaid also shall. Amiss , The sun shineth not good came the door of them , and he. Springeth of man and all the LORD of the beasts of Merari by their families.\n",
            "Discord . 7 And. Infinite ? tempting him as it in the LORD . 30 For it came and. Leummim . And they , saying , named Zacchaeus , to Gath . 24 And. Thunderings , and in there was two goats for us , and wounded men .. Denied him , Sun , and fear of Israel out of Israel took the LORD.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTudPGyD0GMf",
        "outputId": "c98372bb-df42-4962-88f3-c14e3aa041d7"
      },
      "source": [
        "# Here's a LSTM model to generate bible passages\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils\n",
        "\n",
        "# Load in the bible text\n",
        "# load ascii text and covert to lowercase\n",
        "def listToString(s):   \n",
        "    str1 = \" \"    \n",
        "    return (str1.join(s))\n",
        "\n",
        "raw_text = listToString(list(bible)).lower()\n",
        "#filename = \"bible-kjv.txt\"\n",
        "#raw_text = open(filename).read()\n",
        "#raw_text = raw_text.lower()\n",
        "\n",
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  4495207\n",
            "Total Vocab:  49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8DGsHfH07KI",
        "outputId": "16e4bb57-5cc0-4ce5-9821-cb1b0bc3eb06"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  4495107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oAiC_g0WorN"
      },
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDcZ4PIs1ncC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "7b093bc6-c5d6-415e-a485-32aa598945d3"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model.fit(X, y, epochs=20, batch_size=1024*2, callbacks=callbacks_list)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "2195/2195 [==============================] - 191s 85ms/step - loss: 1.2689\n",
            "\n",
            "Epoch 00001: loss improved from inf to 1.26894, saving model to weights-improvement-01-1.2689.hdf5\n",
            "Epoch 2/20\n",
            "2195/2195 [==============================] - 186s 85ms/step - loss: 1.2601\n",
            "\n",
            "Epoch 00002: loss improved from 1.26894 to 1.26011, saving model to weights-improvement-02-1.2601.hdf5\n",
            "Epoch 3/20\n",
            "2195/2195 [==============================] - 186s 85ms/step - loss: 1.2561\n",
            "\n",
            "Epoch 00003: loss improved from 1.26011 to 1.25612, saving model to weights-improvement-03-1.2561.hdf5\n",
            "Epoch 4/20\n",
            "2195/2195 [==============================] - 187s 85ms/step - loss: 1.2530\n",
            "\n",
            "Epoch 00004: loss improved from 1.25612 to 1.25297, saving model to weights-improvement-04-1.2530.hdf5\n",
            "Epoch 5/20\n",
            "1007/2195 [============>.................] - ETA: 1:40 - loss: 1.2486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c07ef9716680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    907\u001b[0m       \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\b'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    406\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrunning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m \u001b[0mimmediately\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mis_alive\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \"\"\"\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Thread.__init__() not called\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_started\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mis_set\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;34m\"\"\"Return true if and only if the internal flag is true.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaVPHvsE0sJJ"
      },
      "source": [
        "\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "# generate characters\n",
        "for i in range(300):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    print(result, end='')\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHPvDbaDBIIX",
        "outputId": "5df5a1d3-336d-4838-9a46-c40a9cffa034"
      },
      "source": [
        "import random\n",
        "p = model.predict(x, verbose=0)\n",
        "p.argmax)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0COvCvl4-aJ"
      },
      "source": [
        "def top_argmax(arr, n):\n",
        "    return np.random.choice(np.argsort(arr)[-3:])\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmAcktonXw7d"
      },
      "source": [
        "# Generate bible verse\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-04-1.2530.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r34fq7miW6pv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}